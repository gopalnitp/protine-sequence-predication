{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.models import Sequential\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15626, 511)\n",
      "(4249, 512)\n"
     ]
    }
   ],
   "source": [
    "data_train=pd.read_csv(\"MergetrainDataSVD.csv\") #read train file\n",
    "data_test=pd.read_csv(\"MergetestDataSVD.csv\")  #read  test fil\n",
    "print data_train.shape\n",
    "print data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>entry</th>\n",
       "      <th>0.entry</th>\n",
       "      <th>entry.entry</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>colm</th>\n",
       "      <th>col10_new_10</th>\n",
       "      <th>col2_new_2</th>\n",
       "      <th>col3_new_3</th>\n",
       "      <th>col4_new_4</th>\n",
       "      <th>col6_new_6</th>\n",
       "      <th>col7_new_7</th>\n",
       "      <th>col_new_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MGINKKDGQPQYAPSHLGTKPVKYKRNKGEKFHDKSNGHPIVMQTKGE</td>\n",
       "      <td>['A7Z570']</td>\n",
       "      <td>0.013624</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>-0.011797</td>\n",
       "      <td>-0.002597</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000152</td>\n",
       "      <td>-0.000167</td>\n",
       "      <td>colm1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MSSVDVLLTVGKLDASLALLTTQDHHVIEFPTVLLPENVKAGSIIK...</td>\n",
       "      <td>['Q12114']</td>\n",
       "      <td>0.005838</td>\n",
       "      <td>-0.003215</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>-0.004258</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>-0.011858</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>colm1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 511 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                  0       entry  \\\n",
       "0           0   MGINKKDGQPQYAPSHLGTKPVKYKRNKGEKFHDKSNGHPIVMQTKGE  ['A7Z570']   \n",
       "1           1  MSSVDVLLTVGKLDASLALLTTQDHHVIEFPTVLLPENVKAGSIIK...  ['Q12114']   \n",
       "\n",
       "    0.entry  entry.entry         2         3         4         5         6  \\\n",
       "0  0.013624     0.001468  0.002604  0.000007  0.001220 -0.011797 -0.002597   \n",
       "1  0.005838    -0.003215 -0.000098 -0.004258  0.002207 -0.011858  0.001375   \n",
       "\n",
       "     ...           498       499   colm  col10_new_10  col2_new_2  col3_new_3  \\\n",
       "0    ...     -0.000152 -0.000167  colm1             0           0           0   \n",
       "1    ...     -0.000328 -0.000109  colm1             0           0           0   \n",
       "\n",
       "   col4_new_4  col6_new_6  col7_new_7  col_new_1  \n",
       "0           0           0           0          1  \n",
       "1           0           0           0          1  \n",
       "\n",
       "[2 rows x 511 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train1=data_train.drop([\"colm\"],axis=1)  #remove colm from train data \n",
    "data_test1=data_test.drop([\"colm\",\"GOTerm\"],axis=1) #remove Goterm and colm\n",
    "X_data_train=data_train1.values\n",
    "X_data_test=data_test1.values\n",
    "X_data_train=X_data_train[:,3:]#remove 1st 3 useless feture\n",
    "X_data_test=X_data_test[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15626, 507)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_data_train[:,:500] # X train final train data\n",
    "Y_train=X_data_train[:,500:] # Y multlevel data\n",
    "X_test=X_data_test[:,:500]   #test data\n",
    "Y_test=X_data_test[:,500:]   #multilevel y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15626, 500)\n",
      "(15626, 7)\n",
      "(4249, 500) (4249, 7)\n"
     ]
    }
   ],
   "source": [
    "print X_train.shape\n",
    "print Y_train.shape\n",
    "print X_test.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[:,1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=sklearn.preprocessing.normalize(X_test, axis=1, copy=True, return_norm=False) #normalize x test\n",
    "X_train=sklearn.preprocessing.normalize(X_train, axis=1, copy=True, return_norm=False)#normalize x train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 300)               150300    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 125)               25125     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 125)               0         \n",
      "=================================================================\n",
      "Total params: 235,625\n",
      "Trainable params: 235,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#encoder model is used to dimensional reduction from 500 to 125\n",
    "Encoder = Sequential()\n",
    "Encoder.add( Dense(300, input_shape = (500,) ) ) #input shape is equal to no of feature in X_train\n",
    "Encoder.add(Activation('sigmoid'))               \n",
    "Encoder.add(Dense(200))\n",
    "Encoder.add(Activation(\"relu\"))\n",
    "Encoder.add(Dense(125))\n",
    "Encoder.add( Activation('sigmoid') )\n",
    "Encoder.summary()\n",
    "# 2 hidden layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 200)               25200     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 300)               60300     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               150500    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 500)               0         \n",
      "=================================================================\n",
      "Total params: 236,000\n",
      "Trainable params: 236,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Decoder model is used to decoding from 125 to 500 feture\n",
    "Decoder = Sequential()\n",
    "Decoder.add( Dense(200, input_shape = (125,)) ) #input shape is output of encoder\n",
    "Decoder.add(Activation(\"sigmoid\"))\n",
    "Decoder.add(Dense(300))\n",
    "Decoder.add(Activation(\"relu\"))\n",
    "Decoder.add(Dense(500))\n",
    "Decoder.add( Activation('sigmoid') )\n",
    "Decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential_1 (Sequential)    (None, 125)               235625    \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 500)               236000    \n",
      "=================================================================\n",
      "Total params: 471,625\n",
      "Trainable params: 471,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "AutoEncoder = Sequential([Encoder, Decoder]) #autoencoder is used for encoding and  decoding both\n",
    "AutoEncoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoEncoder.compile(optimizer='rmsprop', loss='mse',metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint \n",
    "filepath=\"Autoencodermodel.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath,monitor=\"loss\" ,verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "#used to save the model which has less loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "15626/15626 [==============================] - 2s 134us/step - loss: 0.0019 - acc: 0.1507\n",
      "\n",
      "Epoch 00001: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 2/20\n",
      "15626/15626 [==============================] - 2s 139us/step - loss: 0.0019 - acc: 0.1508\n",
      "\n",
      "Epoch 00002: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 3/20\n",
      "15626/15626 [==============================] - 2s 138us/step - loss: 0.0019 - acc: 0.1516\n",
      "\n",
      "Epoch 00003: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 4/20\n",
      "15626/15626 [==============================] - 2s 143us/step - loss: 0.0019 - acc: 0.1511\n",
      "\n",
      "Epoch 00004: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 5/20\n",
      "15626/15626 [==============================] - 2s 140us/step - loss: 0.0019 - acc: 0.1517\n",
      "\n",
      "Epoch 00005: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 6/20\n",
      "15626/15626 [==============================] - 2s 138us/step - loss: 0.0019 - acc: 0.1515\n",
      "\n",
      "Epoch 00006: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 7/20\n",
      "15626/15626 [==============================] - 2s 133us/step - loss: 0.0019 - acc: 0.1514\n",
      "\n",
      "Epoch 00007: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 8/20\n",
      "15626/15626 [==============================] - 2s 128us/step - loss: 0.0019 - acc: 0.1508\n",
      "\n",
      "Epoch 00008: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 9/20\n",
      "15626/15626 [==============================] - 2s 146us/step - loss: 0.0019 - acc: 0.1515\n",
      "\n",
      "Epoch 00009: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 10/20\n",
      "15626/15626 [==============================] - 2s 128us/step - loss: 0.0019 - acc: 0.1517\n",
      "\n",
      "Epoch 00010: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 11/20\n",
      "15626/15626 [==============================] - 2s 145us/step - loss: 0.0019 - acc: 0.1529\n",
      "\n",
      "Epoch 00011: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 12/20\n",
      "15626/15626 [==============================] - 2s 133us/step - loss: 0.0019 - acc: 0.1522\n",
      "\n",
      "Epoch 00012: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 13/20\n",
      "15626/15626 [==============================] - 2s 131us/step - loss: 0.0019 - acc: 0.1529\n",
      "\n",
      "Epoch 00013: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 14/20\n",
      "15626/15626 [==============================] - 2s 132us/step - loss: 0.0019 - acc: 0.1530\n",
      "\n",
      "Epoch 00014: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 15/20\n",
      "15626/15626 [==============================] - 2s 141us/step - loss: 0.0019 - acc: 0.1529\n",
      "\n",
      "Epoch 00015: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 16/20\n",
      "15626/15626 [==============================] - 2s 151us/step - loss: 0.0019 - acc: 0.1531\n",
      "\n",
      "Epoch 00016: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 17/20\n",
      "15626/15626 [==============================] - 2s 132us/step - loss: 0.0019 - acc: 0.1533\n",
      "\n",
      "Epoch 00017: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 18/20\n",
      "15626/15626 [==============================] - 2s 135us/step - loss: 0.0019 - acc: 0.1534\n",
      "\n",
      "Epoch 00018: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 19/20\n",
      "15626/15626 [==============================] - 2s 132us/step - loss: 0.0019 - acc: 0.1532\n",
      "\n",
      "Epoch 00019: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n",
      "Epoch 20/20\n",
      "15626/15626 [==============================] - 2s 131us/step - loss: 0.0019 - acc: 0.1532\n",
      "\n",
      "Epoch 00020: loss improved from 0.00194 to 0.00194, saving model to Autoencodermodel.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f79f8c2cdd0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoEncoder.fit(X_train,X_train,batch_size=64, epochs=20,callbacks=callbacks_list,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "AutoEncoder.save(\"after_AutoEnoder.hdf5\") #save autoencoder model with less loss\n",
    "Encoder.save(\"Enoder_1500.hdf5\") #save encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AutoEncoder.evaluate(X_train[1000].reshape(1,500),X_train[1000].reshape(1,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_autoencoder=Encoder.predict(X_train) #reduce train dimension by encoder model\n",
    "X_test_autoencoder=Encoder.predict(X_test)#reduce test dimension by encoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test=Y_test.astype(\"float32\") #change dtype obj to float\n",
    "Y_train=Y_train.astype(\"float32\") #change dtype obj to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4249, 500)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print X_test.shape\n",
    "print Y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report #for classification report precision,recall and f1-score\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "#BinaryRelevanceis  the simplest technique, which basically treats each label as a separate single class classification problem.\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = BinaryRelevance(svm.SVC(kernel='rbf', class_weight=\"balanced\"))\n",
    "    #BinaryRelevance with svm and kernal is rbf\n",
    "classifier.fit(X_train_autoencoder, Y_train)\n",
    "   # predict\n",
    "Y_predicted_SVM_BinaryRelevance= classifier.predict(X_test_autoencoder) #\n",
    "\n",
    "print \"acc\",accuracy_score(Y_test,Y_predicted_SVM_BinaryRelevance)\n",
    "print classification_report(Y_test,Y_predicted_SVM_BinaryRelevance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.4290421275594257\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.21      0.32       282\n",
      "          1       0.88      0.33      0.48       389\n",
      "          2       0.64      0.59      0.62      1567\n",
      "          3       0.94      0.87      0.90       557\n",
      "          4       0.71      0.35      0.47       989\n",
      "          5       0.54      0.08      0.13       465\n",
      "          6       0.76      0.24      0.36       129\n",
      "\n",
      "avg / total       0.71      0.46      0.53      4378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#BinaryRelevance with rbf\n",
    "classifier = BinaryRelevance(RandomForestClassifier(class_weight=\"balanced\"))\n",
    "\n",
    "classifier.fit(X_train_autoencoder, Y_train)\n",
    "# predict\n",
    "Y_predicted_rbf_BinaryRelevance= classifier.predict(X_test_autoencoder)\n",
    "\n",
    "print \"acc\",accuracy_score(Y_test,Y_predicted_rbf_BinaryRelevance)\n",
    "print classification_report(Y_test,Y_predicted_rbf_BinaryRelevance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5342433513767946\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.16      0.26       282\n",
      "          1       0.87      0.34      0.49       389\n",
      "          2       0.62      0.58      0.60      1567\n",
      "          3       0.93      0.87      0.90       557\n",
      "          4       0.56      0.53      0.55       989\n",
      "          5       0.33      0.26      0.29       465\n",
      "          6       0.52      0.57      0.54       129\n",
      "\n",
      "avg / total       0.64      0.53      0.56      4378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using classifier chains and rbf\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "\n",
    "# initialize classifier chains multi-label classifier\n",
    "# with a gaussian naive bayes base classifier\n",
    "classifier = ClassifierChain(RandomForestClassifier(class_weight=\"balanced\"))\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train_autoencoder, Y_train)\n",
    "\n",
    "# predict\n",
    "Y_predicted_cChain = classifier.predict(X_test_autoencoder)\n",
    "\n",
    "acc=accuracy_score(Y_test,predictions)\n",
    "print acc\n",
    "print classification_report(Y_test,Y_predicted_cChain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48105436573311366\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "#multi-label version of kNN is represented by MLkNN\n",
    "\n",
    "classifier = MLkNN(k=7) #no of cluster \n",
    "\n",
    "# train\n",
    "classifier.fit(X_train_autoencoder, Y_train)\n",
    "\n",
    "# predict\n",
    "predictions = classifier.predict(X_test_autoencoder)\n",
    "\n",
    "print accuracy_score(Y_test,predictions)\n",
    "print classification_report(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "#sparse_y_test=sparse.csr_matrix(Y_test) to change numpy array to sparse matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "predictions=csr_matrix(predictions, dtype=np.int8).toarray() #convert sparse matrix to an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predicted_df=predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(Y_test.argmax(axis=1), Y_predicted_df.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision\n",
      "0.524084098219\n",
      "Average Recall\n",
      "0.538675766847\n"
     ]
    }
   ],
   "source": [
    "listMetrics =[]\n",
    "listMetrics.append( [\"TP\",\"FP\",\"TN\",\"FN\",\"Precision\",\"Recall\"])\n",
    "totalPrecision = 0.0\n",
    "totalRecall = 0.0\n",
    "for i in range(Y_test.shape[0]):\n",
    "    listM = []\n",
    "    truePositive = 0.0\n",
    "    trueNegative = 0.0\n",
    "    falsePositive = 0.0\n",
    "    falseNegative = 0.0\n",
    "    precision = 0.0\n",
    "    recall = 0.0\n",
    "    for j in range(Y_test.shape[1]):\n",
    "        if Y_predicted_df[i,j] == 1:\n",
    "            if Y_test[i,j] == 1:\n",
    "                truePositive = truePositive + 1\n",
    "            else:    \n",
    "                falsePositive = falsePositive + 1\n",
    "        else:\n",
    "            if Y_test[i,j] == 1:\n",
    "                falseNegative = falseNegative + 1\n",
    "            else:\n",
    "                trueNegative = trueNegative + 1\n",
    "    try:\n",
    "        precision = truePositive/(truePositive + falsePositive)\n",
    "    except ZeroDivisionError:\n",
    "        precision=0\n",
    "    totalPrecision = totalPrecision + precision\n",
    "    try:\n",
    "        recall = truePositive/(truePositive + falseNegative)\n",
    "    except ZeroDivisionError:\n",
    "        recall=0\n",
    "    totalRecall = totalRecall + recall\n",
    "    \n",
    "    listM.append(truePositive)\n",
    "    listM.append(falsePositive)\n",
    "    listM.append(trueNegative)\n",
    "    listM.append(falseNegative)\n",
    "    listM.append(precision)\n",
    "    listM.append(recall)\n",
    "    listMetrics.append(listM)\n",
    "avgPrecision = totalPrecision / (Y_test.shape[0])\n",
    "avgRecall = totalRecall / (Y_test.shape[0])\n",
    "print(\"Average Precision\")\n",
    "print(avgPrecision)\n",
    "print(\"Average Recall\")\n",
    "print(avgRecall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nclasses = 7.0\n",
    "#nclasses1 = 7\n",
    " \n",
    "#class_weights = {k:len(Y_train)/(nclasses*(Y_train[:,k]==1).sum()) for k in range(nclasses1)}\n",
    "\n",
    "#print class_weights\n",
    "\n",
    "#model.fit(X_new_train,Y_train, class_weight=class_weights, epochs=250,batch_size=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
